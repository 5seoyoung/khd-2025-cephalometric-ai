# -*- coding: utf-8 -*-
"""
Demo Inference Engine
ì‹¤ì œ AI ëª¨ë¸ ì—†ì´ ëœë“œë§ˆí¬ë¥¼ ì¶”ë¡ í•˜ëŠ” ë°ëª¨ìš© ì—”ì§„ì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ëŒ€í‘œ ë„ë©´ ë§¤ì¹­ (SHA256 í•´ì‹œ ê¸°ë°˜)
- í‰ê·  í˜•ìƒ ê¸°ë°˜ íˆãƒ¥ãƒ¼ë¦¬ìŠ¤í‹± ì¶”ë¡ 
- FH ê¸°ì¤€ ì¢Œí‘œ ë³´ì • (Or/Po ì•µì»¤ í¬ì¸íŠ¸)
- ê²°ì •ë¡ ì  ë…¸ì´ì¦ˆ ì¶”ê°€
"""

import json
import os
import hashlib
import time
import numpy as np
from PIL import Image
from typing import Dict, Tuple, Optional, Any, List

# 19ê°œ ëœë“œë§ˆí¬ ëª©ë¡
LANDMARK_NAMES = [
    "N", "S", "Ar", "Or", "Po", "A", "B", "U1", "Ls", "Pog'",
    "Go", "Pog", "Me", "ANS", "PNS", "Gn", "L1", "Li", "Pn"
]

def load_json_config(file_path: str) -> Dict:
    """JSON ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    except json.JSONDecodeError as e:
        raise ValueError(f"JSON íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {file_path}, {e}")

def hash_image(pil_image: Image.Image) -> str:
    """
    ì´ë¯¸ì§€ì˜ SHA256 í•´ì‹œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    ì¼ê´€ì„±ì„ ìœ„í•´ 256x256 ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™” í›„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    # ì •ê·œí™”: 256x256 ê·¸ë ˆì´ìŠ¤ì¼€ì¼
    normalized = pil_image.convert("L").resize((256, 256))
    image_bytes = normalized.tobytes()
    
    # SHA256 í•´ì‹œ ê³„ì‚°
    hash_object = hashlib.sha256(image_bytes)
    return hash_object.hexdigest()

def scale_normalized_landmarks(normalized_landmarks: Dict[str, Tuple[float, float]], 
                              image_width: int, 
                              image_height: int) -> Dict[str, Tuple[float, float]]:
    """
    ì •ê·œí™”ëœ ì¢Œí‘œ(0~1)ë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶° ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤.
    """
    scaled = {}
    for name, (norm_x, norm_y) in normalized_landmarks.items():
        x = float(norm_x * image_width)
        y = float(norm_y * image_height)
        scaled[name] = (x, y)
    return scaled

def similarity_transform_2d(points: Dict[str, Tuple[float, float]], 
                           src_anchor1: Tuple[float, float], 
                           src_anchor2: Tuple[float, float],
                           dst_anchor1: Tuple[float, float], 
                           dst_anchor2: Tuple[float, float]) -> Dict[str, Tuple[float, float]]:
    """
    ë‘ ì•µì»¤ í¬ì¸íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ similarity transformationì„ ì ìš©í•©ë‹ˆë‹¤.
    ì£¼ë¡œ FH plane ì •ë ¬ì— ì‚¬ìš© (Or, Po ê¸°ì¤€)
    """
    import math
    
    # ì›ë³¸ ë²¡í„°
    src_dx = src_anchor2[0] - src_anchor1[0]
    src_dy = src_anchor2[1] - src_anchor1[1]
    src_dist = math.sqrt(src_dx**2 + src_dy**2)
    
    # ëª©í‘œ ë²¡í„°  
    dst_dx = dst_anchor2[0] - dst_anchor1[0]
    dst_dy = dst_anchor2[1] - dst_anchor1[1]
    dst_dist = math.sqrt(dst_dx**2 + dst_dy**2)
    
    if src_dist == 0 or dst_dist == 0:
        return points  # ë³€í™˜ ë¶ˆê°€
    
    # ìŠ¤ì¼€ì¼ ê³„ì‚°
    scale = dst_dist / src_dist
    
    # íšŒì „ ê°ë„ ê³„ì‚°
    src_angle = math.atan2(src_dy, src_dx)
    dst_angle = math.atan2(dst_dy, dst_dx)
    rotation = dst_angle - src_angle
    
    cos_r = math.cos(rotation)
    sin_r = math.sin(rotation)
    
    # ë³€í™˜ ì ìš©
    transformed = {}
    for name, (x, y) in points.items():
        # 1. í‰í–‰ì´ë™ (src_anchor1ì„ ì›ì ìœ¼ë¡œ)
        tx = x - src_anchor1[0]
        ty = y - src_anchor1[1]
        
        # 2. íšŒì „ + ìŠ¤ì¼€ì¼
        rx = scale * (cos_r * tx - sin_r * ty)
        ry = scale * (sin_r * tx + cos_r * ty)
        
        # 3. í‰í–‰ì´ë™ (dst_anchor1ìœ¼ë¡œ)
        final_x = rx + dst_anchor1[0]
        final_y = ry + dst_anchor1[1]
        
        transformed[name] = (float(final_x), float(final_y))
    
    return transformed

def add_deterministic_jitter(points: Dict[str, Tuple[float, float]], 
                           sigma: float = 1.5, 
                           seed: int = 42) -> Dict[str, Tuple[float, float]]:
    """
    ê²°ì •ë¡ ì  ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤ (ì‹œë“œ ê³ ì •ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥).
    """
    rng = np.random.RandomState(seed)
    jittered = {}
    
    for name, (x, y) in points.items():
        # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
        dx, dy = rng.normal(0, sigma, 2)
        jittered[name] = (float(x + dx), float(y + dy))
    
    return jittered

def clamp_points_to_image(points: Dict[str, Tuple[float, float]], 
                         image_width: int, 
                         image_height: int) -> Dict[str, Tuple[float, float]]:
    """
    ì¢Œí‘œê°€ ì´ë¯¸ì§€ ê²½ê³„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ í´ë¨í•‘í•©ë‹ˆë‹¤.
    """
    clamped = {}
    for name, (x, y) in points.items():
        clamped_x = max(0, min(x, image_width - 1))
        clamped_y = max(0, min(y, image_height - 1))
        clamped[name] = (float(clamped_x), float(clamped_y))
    
    return clamped

class DemoInference:
    """
    ë°ëª¨ìš© ëœë“œë§ˆí¬ ì¶”ë¡  ì—”ì§„
    """
    
    def __init__(self, 
                 demo_config_path: str = "data/clinical_standards/demo_landmarks.json",
                 mean_shape_path: str = "data/clinical_standards/mean_shape.json",
                 seed: int = 42):
        """
        ì´ˆê¸°í™”
        
        Args:
            demo_config_path: ëŒ€í‘œ ë„ë©´ ì„¤ì • íŒŒì¼ ê²½ë¡œ
            mean_shape_path: í‰ê·  í˜•ìƒ íŒŒì¼ ê²½ë¡œ  
            seed: ë‚œìˆ˜ ì‹œë“œ
        """
        self.seed = seed
        self.demo_config = load_json_config(demo_config_path)
        self.mean_shape = load_json_config(mean_shape_path)
        
        print(f"âœ… DemoInference ì´ˆê¸°í™” ì™„ë£Œ (seed={seed})")
    
    def load_precomputed_if_match(self, pil_image: Image.Image) -> Tuple[Optional[Dict], Optional[str]]:
        """
        ì´ë¯¸ì§€ê°€ ëŒ€í‘œ ë„ë©´ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì¼ì¹˜í•˜ë©´ ì‚¬ì „ ê³„ì‚°ëœ ì¢Œí‘œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        image_hash = hash_image(pil_image)
        demo_hash = self.demo_config.get("image_sha256", "")
        
        if image_hash == demo_hash:
            # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ í˜„ì¬ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶° ìŠ¤ì¼€ì¼ë§
            width, height = pil_image.size
            landmarks = scale_normalized_landmarks(
                self.demo_config["landmarks"], width, height
            )
            return landmarks, "precomputed"
        
        return None, None
    
    def heuristic_landmarks(self, pil_image: Image.Image) -> Dict[str, Tuple[float, float]]:
        """
        í‰ê·  í˜•ìƒ ê¸°ë°˜ìœ¼ë¡œ íˆãƒ¥ãƒ¼ë¦¬ìŠ¤í‹± ëœë“œë§ˆí¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        """
        width, height = pil_image.size
        
        # í‰ê·  í˜•ìƒì„ í˜„ì¬ ì´ë¯¸ì§€ í¬ê¸°ì— ìŠ¤ì¼€ì¼ë§
        landmarks = scale_normalized_landmarks(
            self.mean_shape["landmarks"], width, height
        )
        
        return landmarks
    
    def predict_landmarks(self, 
                         pil_image: Image.Image, 
                         anchors: Optional[Dict[str, Tuple[float, float]]] = None) -> Tuple[Dict[str, Tuple[float, float]], str]:
        """
        ì´ë¯¸ì§€ì—ì„œ ëœë“œë§ˆí¬ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        
        Args:
            pil_image: ì…ë ¥ ì´ë¯¸ì§€
            anchors: ì‚¬ìš©ìê°€ ì œê³µí•œ ì•µì»¤ í¬ì¸íŠ¸ (Or, Po ë“±)
        
        Returns:
            (landmarks, mode) íŠœí”Œ
            - landmarks: ì˜ˆì¸¡ëœ ëœë“œë§ˆí¬ ì¢Œí‘œ
            - mode: "precomputed" | "heuristic" | "manual_corrected"
        """
        start_time = time.perf_counter()
        width, height = pil_image.size
        
        # 1ë‹¨ê³„: ëŒ€í‘œ ë„ë©´ ë§¤ì¹­ ì‹œë„
        landmarks, mode = self.load_precomputed_if_match(pil_image)
        
        if landmarks is None:
            # 2ë‹¨ê³„: íˆãƒ¥ãƒ¼ë¦¬ìŠ¤í‹± ìƒì„±
            landmarks = self.heuristic_landmarks(pil_image)
            mode = "heuristic"
            
            # 3ë‹¨ê³„: ì•µì»¤ ê¸°ë°˜ ë³´ì • (Or, Po ì œê³µ ì‹œ)
            if anchors and "Or" in anchors and "Po" in anchors:
                # í˜„ì¬ Or, Po ìœ„ì¹˜
                current_or = landmarks["Or"]
                current_po = landmarks["Po"]
                
                # ì‚¬ìš©ì ì œê³µ Or, Po ìœ„ì¹˜
                target_or = anchors["Or"]
                target_po = anchors["Po"]
                
                # Similarity transformation ì ìš©
                landmarks = similarity_transform_2d(
                    landmarks, current_or, current_po, target_or, target_po
                )
                mode = "manual_corrected"
        
        # 4ë‹¨ê³„: ê²°ì •ë¡ ì  ë…¸ì´ì¦ˆ ì¶”ê°€
        landmarks = add_deterministic_jitter(landmarks, sigma=1.5, seed=self.seed)
        
        # 5ë‹¨ê³„: ì´ë¯¸ì§€ ê²½ê³„ í´ë¨í•‘
        landmarks = clamp_points_to_image(landmarks, width, height)
        
        elapsed = time.perf_counter() - start_time
        print(f"ğŸ¯ ëœë“œë§ˆí¬ ì˜ˆì¸¡ ì™„ë£Œ: {mode} ({elapsed*1000:.1f}ms)")
        
        return landmarks, mode
    
    def get_inference_info(self) -> Dict[str, Any]:
        """
        ì¶”ë¡  ì—”ì§„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        return {
            "engine": "DemoInference",
            "version": "1.0",
            "seed": self.seed,
            "demo_hash": self.demo_config.get("image_sha256", "")[:16] + "...",
            "landmark_count": len(LANDMARK_NAMES),
            "supported_modes": ["precomputed", "heuristic", "manual_corrected"]
        }

def test_demo_inference():
    """
    ë°ëª¨ ì¶”ë¡  ì—”ì§„ í…ŒìŠ¤íŠ¸
    """
    print("ğŸ§ª DemoInference í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # 1. ì—”ì§„ ì´ˆê¸°í™”
        engine = DemoInference()
        
        # 2. ì •ë³´ ì¶œë ¥
        info = engine.get_inference_info()
        print("ğŸ“‹ ì—”ì§„ ì •ë³´:")
        for key, value in info.items():
            print(f"   {key}: {value}")
        
        # 3. í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„± (800x600 í°ìƒ‰ ì´ë¯¸ì§€)
        test_image = Image.new("RGB", (800, 600), color="white")
        
        # 4. ëœë“œë§ˆí¬ ì˜ˆì¸¡ (íˆãƒ¥ãƒ¼ë¦¬ìŠ¤í‹± ëª¨ë“œ)
        print("\nğŸ¯ íˆãƒ¥ãƒ¼ë¦¬ìŠ¤í‹± ëª¨ë“œ í…ŒìŠ¤íŠ¸:")
        landmarks, mode = engine.predict_landmarks(test_image)
        print(f"   ëª¨ë“œ: {mode}")
        print(f"   ëœë“œë§ˆí¬ ê°œìˆ˜: {len(landmarks)}")
        print(f"   ìƒ˜í”Œ ì¢Œí‘œ (N): {landmarks['N']}")
        print(f"   ìƒ˜í”Œ ì¢Œí‘œ (A): {landmarks['A']}")
        
        # 5. ì•µì»¤ ë³´ì • í…ŒìŠ¤íŠ¸
        print("\nğŸ”§ ì•µì»¤ ë³´ì • í…ŒìŠ¤íŠ¸:")
        anchors = {"Or": (450, 200), "Po": (300, 220)}
        landmarks_corrected, mode_corrected = engine.predict_landmarks(test_image, anchors=anchors)
        print(f"   ë³´ì • ëª¨ë“œ: {mode_corrected}")
        print(f"   ë³´ì •ëœ Or: {landmarks_corrected['Or']}")
        print(f"   ë³´ì •ëœ Po: {landmarks_corrected['Po']}")
        
        # 6. ì¬í˜„ì„± í…ŒìŠ¤íŠ¸ (ê°™ì€ ì‹œë“œë¡œ 2ë²ˆ ì‹¤í–‰)
        print("\nğŸ”„ ì¬í˜„ì„± í…ŒìŠ¤íŠ¸:")
        landmarks1, _ = engine.predict_landmarks(test_image)
        landmarks2, _ = engine.predict_landmarks(test_image)
        
        # N í¬ì¸íŠ¸ë¡œ ì¬í˜„ì„± í™•ì¸
        diff = abs(landmarks1["N"][0] - landmarks2["N"][0]) + abs(landmarks1["N"][1] - landmarks2["N"][1])
        print(f"   ì¢Œí‘œ ì°¨ì´ (N): {diff:.6f} (0ì´ë©´ ì™„ì „ ì¬í˜„)")
        
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_demo_inference()